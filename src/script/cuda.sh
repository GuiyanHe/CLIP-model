#!/bin/bash

set -e

echo "ðŸš€ æœ€ç»ˆ CUDA çŽ¯å¢ƒé…ç½®..."
echo ""

# 1. æ£€æŸ¥ conda æ˜¯å¦åˆå§‹åŒ–
if ! command -v conda &> /dev/null; then
    echo "âŒ conda å‘½ä»¤æ‰¾ä¸åˆ°ï¼Œæ­£åœ¨åˆå§‹åŒ–..."
    $HOME/miniforge3/bin/conda init bash
    $HOME/miniforge3/bin/conda init zsh
    source ~/.bashrc
fi

# 2. ç¡®ä¿åœ¨ clip çŽ¯å¢ƒ
echo "ðŸ“¦ ç¡®ä¿ clip çŽ¯å¢ƒ..."
conda activate clip 2>/dev/null || {
    echo "âš ï¸  æ— æ³•æ¿€æ´» clipï¼Œå°è¯•åˆ›å»º..."
    conda create -n clip python=3.10 -y
    conda activate clip
}

# 3. åˆ›å»º CUDA æ¿€æ´»è„šæœ¬
CONDA_ENV=$CONDA_PREFIX
mkdir -p $CONDA_ENV/etc/conda/activate.d
mkdir -p $CONDA_ENV/etc/conda/deactivate.d

echo "ðŸ“ åˆ›å»ºæ¿€æ´»è„šæœ¬..."

cat > $CONDA_ENV/etc/conda/activate.d/cuda_env.sh << 'SCRIPT'
#!/bin/bash
export CUDA_HOME=$CONDA_PREFIX
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export CUDA_VISIBLE_DEVICES=0
SCRIPT

cat > $CONDA_ENV/etc/conda/deactivate.d/cuda_env.sh << 'SCRIPT'
#!/bin/bash
unset CUDA_HOME
unset CUDA_VISIBLE_DEVICES
SCRIPT

chmod +x $CONDA_ENV/etc/conda/activate.d/cuda_env.sh
chmod +x $CONDA_ENV/etc/conda/deactivate.d/cuda_env.sh

# 4. éªŒè¯ CUDA
echo ""
echo "âœ… éªŒè¯ CUDA..."
export CUDA_HOME=$CONDA_PREFIX
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

nvcc --version
nvidia-smi -L

# 5. é‡è£… ONNX Runtime GPU
echo ""
echo "ðŸ”„ é‡è£… ONNX Runtime GPU..."
pip uninstall onnxruntime -y
pip install onnxruntime-gpu

# 6. æœ€ç»ˆéªŒè¯
echo ""
echo "âœ… æœ€ç»ˆéªŒè¯..."
python << 'PYTHON'
import onnxruntime as ort
import torch

print("\n" + "="*70)
print("ðŸŽ‰ æœ€ç»ˆé…ç½®éªŒè¯")
print("="*70)

providers = ort.get_available_providers()
print(f"\nâœ… ONNX Runtime Providers:")
for p in providers:
    marker = "âœ…" if "CUDA" in p or "Tensor" in p else "â„¹ï¸"
    print(f"   {marker} {p}")

if torch.cuda.is_available():
    print(f"\nâœ… PyTorch GPU:")
    print(f"   GPU: {torch.cuda.get_device_name(0)}")
    print(f"   CUDA: {torch.version.cuda}")
    print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

if 'CUDAExecutionProvider' in providers:
    print(f"\nâœ… GPU åŠ é€Ÿå·²å¯ç”¨ï¼å¯ä»¥ä½¿ç”¨è¯Šæ–­è„šæœ¬äº†")
else:
    print(f"\nâŒ CUDA æä¾›è€…ä»æœªå¯ç”¨")

print("="*70)
PYTHON

echo ""
echo "âœ¨ å®Œæˆï¼"