{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-18T17:11:08.188107532Z",
     "start_time": "2026-02-18T17:11:02.177229870Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==================== 1. Êï∞ÊçÆÂä†ËΩΩ ====================\n",
    "class CLIPEvaluator:\n",
    "    def __init__(self, fp32_model_path, int8_model_path, image_dir, annotations_path):\n",
    "        self.fp32_model_path = fp32_model_path\n",
    "        self.int8_model_path = int8_model_path\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.annotations_path = annotations_path\n",
    "\n",
    "        # ÂàùÂßãÂåñ‰ºöËØù\n",
    "        self.sess_fp32 = ort.InferenceSession(str(fp32_model_path))\n",
    "        self.sess_int8 = ort.InferenceSession(str(int8_model_path))\n",
    "\n",
    "        # Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                std=[0.26862954, 0.26130258, 0.27577711]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # Âä†ËΩΩÊ†áÊ≥®\n",
    "        with open(annotations_path) as f:\n",
    "            self.coco = json.load(f)\n",
    "\n",
    "    def extract_image_features(self, model_type='fp32'):\n",
    "        \"\"\"ÊèêÂèñÊâÄÊúâÂõæÂÉèÁâπÂæÅ\"\"\"\n",
    "        sess = self.sess_fp32 if model_type == 'fp32' else self.sess_int8\n",
    "        input_name = sess.get_inputs()[0].name\n",
    "\n",
    "        features = []\n",
    "        image_ids = []\n",
    "\n",
    "        for img_info in tqdm(self.coco['images'][:1000], desc=f\"Extracting {model_type} image features\"):\n",
    "            img_path = self.image_dir / img_info['file_name']\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_tensor = self.preprocess(img).unsqueeze(0).numpy()\n",
    "\n",
    "                feat = sess.run(None, {input_name: img_tensor})[0]\n",
    "                features.append(feat)\n",
    "                image_ids.append(img_info['id'])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return np.concatenate(features), image_ids\n",
    "\n",
    "    def extract_text_features(self, captions, model_type='fp32'):\n",
    "        \"\"\"ÊèêÂèñÊñáÊú¨ÁâπÂæÅ\"\"\"\n",
    "        sess = self.sess_fp32 if model_type == 'fp32' else self.sess_int8\n",
    "        input_name = sess.get_inputs()[0].name\n",
    "\n",
    "        features = []\n",
    "        for caption in tqdm(captions, desc=f\"Extracting {model_type} text features\"):\n",
    "            # ËøôÈáåÈúÄË¶ÅÁî® clip.tokenize\n",
    "            tokens = clip.tokenize([caption]).numpy()\n",
    "\n",
    "            feat = sess.run(None, {input_name: tokens})[0]\n",
    "            features.append(feat)\n",
    "\n",
    "        return np.concatenate(features)\n",
    "\n",
    "    # ==================== 2. ËØÑ‰º∞ÊåáÊ†á ====================\n",
    "\n",
    "    def compute_top_k_accuracy(self, image_feats, text_feats, k_values=[1, 5, 10]):\n",
    "        \"\"\"ËÆ°ÁÆó Top-K ÂëΩ‰∏≠Áéá\"\"\"\n",
    "        # ÂΩí‰∏ÄÂåñ\n",
    "        image_feats_norm = image_feats / (np.linalg.norm(image_feats, axis=1, keepdims=True) + 1e-7)\n",
    "        text_feats_norm = text_feats / (np.linalg.norm(text_feats, axis=1, keepdims=True) + 1e-7)\n",
    "\n",
    "        # ËÆ°ÁÆóÁõ∏‰ººÂ∫¶Áü©Èòµ\n",
    "        similarity = text_feats_norm @ image_feats_norm.T  # (num_text, num_images)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for k in k_values:\n",
    "            # ÂØπÊØè‰∏™ÊñáÊú¨ÔºåÊâæÊéíÂêçÂâçKÁöÑÂõæÂÉè\n",
    "            top_k_indices = np.argsort(-similarity, axis=1)[:, :k]\n",
    "\n",
    "            # Ê£ÄÊü•ÊòØÂê¶ÊúâÂåπÈÖçÔºàÂÅáËÆæÁ¨¨i‰∏™ÊñáÊú¨ÂØπÂ∫îÁ¨¨i‰∏™ÂõæÂÉèÔºâ\n",
    "            correct = 0\n",
    "            for i, top_k in enumerate(top_k_indices):\n",
    "                if i in top_k:\n",
    "                    correct += 1\n",
    "\n",
    "            accuracy = correct / len(similarity)\n",
    "            results[f'Top-{k}'] = accuracy\n",
    "\n",
    "        return results\n",
    "\n",
    "    def compute_mrr(self, image_feats, text_feats):\n",
    "        \"\"\"ËÆ°ÁÆóÂπ≥ÂùáÊéíÂêçÂÄíÊï∞ (Mean Reciprocal Rank)\"\"\"\n",
    "        image_feats_norm = image_feats / (np.linalg.norm(image_feats, axis=1, keepdims=True) + 1e-7)\n",
    "        text_feats_norm = text_feats / (np.linalg.norm(text_feats, axis=1, keepdims=True) + 1e-7)\n",
    "\n",
    "        similarity = text_feats_norm @ image_feats_norm.T\n",
    "\n",
    "        mrr_scores = []\n",
    "        for i in range(len(similarity)):\n",
    "            # Ê≠£Á°ÆÁ≠îÊ°àÁöÑÊéíÂêç\n",
    "            rank = np.argsort(-similarity[i]).tolist().index(i) + 1\n",
    "            mrr_scores.append(1 / rank)\n",
    "\n",
    "        return np.mean(mrr_scores)\n",
    "\n",
    "    def compute_recall_at_k(self, image_feats, text_feats, k_values=[1, 5, 10]):\n",
    "        \"\"\"ËÆ°ÁÆó Recall@K\"\"\"\n",
    "        image_feats_norm = image_feats / (np.linalg.norm(image_feats, axis=1, keepdims=True) + 1e-7)\n",
    "        text_feats_norm = text_feats / (np.linalg.norm(text_feats, axis=1, keepdims=True) + 1e-7)\n",
    "\n",
    "        similarity = text_feats_norm @ image_feats_norm.T\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for k in k_values:\n",
    "            top_k_indices = np.argsort(-similarity, axis=1)[:, :k]\n",
    "\n",
    "            recall = 0\n",
    "            for i, top_k in enumerate(top_k_indices):\n",
    "                if i in top_k:\n",
    "                    recall += 1\n",
    "\n",
    "            recall = recall / len(similarity)\n",
    "            results[f'Recall@{k}'] = recall\n",
    "\n",
    "        return results\n",
    "\n",
    "    def compute_similarity_distribution(self, image_feats, text_feats):\n",
    "        \"\"\"ËÆ°ÁÆóÁõ∏‰ººÂ∫¶ÂàÜÂ∏ÉÁªüËÆ°\"\"\"\n",
    "        image_feats_norm = image_feats / (np.linalg.norm(image_feats, axis=1, keepdims=True) + 1e-7)\n",
    "        text_feats_norm = text_feats / (np.linalg.norm(text_feats, axis=1, keepdims=True) + 1e-7)\n",
    "\n",
    "        similarity = text_feats_norm @ image_feats_norm.T\n",
    "\n",
    "        # ÂØπËßíÁ∫øÊòØÊ≠£Á°ÆÂåπÈÖç\n",
    "        correct_sim = np.diag(similarity)\n",
    "        # ÈùûÂØπËßíÁ∫øÊòØÈîôËØØÂåπÈÖç\n",
    "        incorrect_sim = similarity[~np.eye(len(similarity), dtype=bool)]\n",
    "\n",
    "        return {\n",
    "            'correct_mean': np.mean(correct_sim),\n",
    "            'correct_std': np.std(correct_sim),\n",
    "            'incorrect_mean': np.mean(incorrect_sim),\n",
    "            'incorrect_std': np.std(incorrect_sim),\n",
    "            'margin': np.mean(correct_sim) - np.mean(incorrect_sim)\n",
    "        }\n",
    "\n",
    "    # ==================== 3. ÂÆåÊï¥ËØÑ‰º∞ ====================\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"ÂÆåÊï¥ËØÑ‰º∞ÊµÅÁ®ã\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"üìä CLIP ÈáèÂåñÂâçÂêéÂØπÊØîËØÑ‰º∞\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # ÊèêÂèñÁâπÂæÅ\n",
    "        print(\"\\nüîç ÊèêÂèñ FP32 ÁâπÂæÅ...\")\n",
    "        img_feats_fp32, img_ids = self.extract_image_features('fp32')\n",
    "        text_feats_fp32 = self.extract_text_features(\n",
    "            [ann['caption'] for ann in self.coco['annotations'][:1000]],\n",
    "            'fp32'\n",
    "        )\n",
    "\n",
    "        print(\"\\nüîç ÊèêÂèñ INT8 ÁâπÂæÅ...\")\n",
    "        img_feats_int8, _ = self.extract_image_features('int8')\n",
    "        text_feats_int8 = self.extract_text_features(\n",
    "            [ann['caption'] for ann in self.coco['annotations'][:1000]],\n",
    "            'int8'\n",
    "        )\n",
    "\n",
    "        # ËØÑ‰º∞\n",
    "        print(\"\\nüìä ËÆ°ÁÆóËØÑ‰º∞ÊåáÊ†á...\")\n",
    "\n",
    "        results = {\n",
    "            'FP32': {},\n",
    "            'INT8': {},\n",
    "            'Delta': {}\n",
    "        }\n",
    "\n",
    "        # Top-K Accuracy\n",
    "        top_k_fp32 = self.compute_top_k_accuracy(img_feats_fp32, text_feats_fp32)\n",
    "        top_k_int8 = self.compute_top_k_accuracy(img_feats_int8, text_feats_int8)\n",
    "\n",
    "        results['FP32'].update(top_k_fp32)\n",
    "        results['INT8'].update(top_k_int8)\n",
    "\n",
    "        for k in top_k_fp32.keys():\n",
    "            results['Delta'][k] = top_k_fp32[k] - top_k_int8[k]\n",
    "\n",
    "        # MRR\n",
    "        mrr_fp32 = self.compute_mrr(img_feats_fp32, text_feats_fp32)\n",
    "        mrr_int8 = self.compute_mrr(img_feats_int8, text_feats_int8)\n",
    "\n",
    "        results['FP32']['MRR'] = mrr_fp32\n",
    "        results['INT8']['MRR'] = mrr_int8\n",
    "        results['Delta']['MRR'] = mrr_fp32 - mrr_int8\n",
    "\n",
    "        # Recall@K\n",
    "        recall_fp32 = self.compute_recall_at_k(img_feats_fp32, text_feats_fp32)\n",
    "        recall_int8 = self.compute_recall_at_k(img_feats_int8, text_feats_int8)\n",
    "\n",
    "        results['FP32'].update(recall_fp32)\n",
    "        results['INT8'].update(recall_int8)\n",
    "\n",
    "        for k in recall_fp32.keys():\n",
    "            results['Delta'][k] = recall_fp32[k] - recall_int8[k]\n",
    "\n",
    "        # Áõ∏‰ººÂ∫¶ÂàÜÂ∏É\n",
    "        sim_dist_fp32 = self.compute_similarity_distribution(img_feats_fp32, text_feats_fp32)\n",
    "        sim_dist_int8 = self.compute_similarity_distribution(img_feats_int8, text_feats_int8)\n",
    "\n",
    "        results['FP32']['similarity_dist'] = sim_dist_fp32\n",
    "        results['INT8']['similarity_dist'] = sim_dist_int8\n",
    "\n",
    "        # ÊâìÂç∞ÁªìÊûú\n",
    "        self.print_results(results)\n",
    "        self.visualize_results(results)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def print_results(self, results):\n",
    "        \"\"\"ÊâìÂç∞ÁªìÊûú\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä ËØÑ‰º∞ÁªìÊûú\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        print(f\"\\n{'ÊåáÊ†á':20s} {'FP32':15s} {'INT8':15s} {'Á≤æÂ∫¶ÊçüÂ§±':15s}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        for key in results['FP32'].keys():\n",
    "            if key != 'similarity_dist':\n",
    "                fp32_val = results['FP32'][key]\n",
    "                int8_val = results['INT8'][key]\n",
    "                delta = results['Delta'][key]\n",
    "\n",
    "                if isinstance(fp32_val, float):\n",
    "                    print(f\"{key:20s} {fp32_val:15.4f} {int8_val:15.4f} {delta:15.4f}\")\n",
    "\n",
    "        print(\"\\n„ÄêÁõ∏‰ººÂ∫¶ÂàÜÂ∏ÉÁªüËÆ°„Äë\")\n",
    "        print(f\"{'':20s} {'FP32':15s} {'INT8':15s}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        for stat_key in ['correct_mean', 'incorrect_mean', 'margin']:\n",
    "            fp32_val = results['FP32']['similarity_dist'][stat_key]\n",
    "            int8_val = results['INT8']['similarity_dist'][stat_key]\n",
    "            print(f\"{stat_key:20s} {fp32_val:15.4f} {int8_val:15.4f}\")\n",
    "\n",
    "    def visualize_results(self, results):\n",
    "        \"\"\"ÂèØËßÜÂåñÁªìÊûú\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "        # 1. Top-K Accuracy ÂØπÊØî\n",
    "        ax = axes[0, 0]\n",
    "        k_values = [1, 5, 10]\n",
    "        fp32_accs = [results['FP32'][f'Top-{k}'] for k in k_values]\n",
    "        int8_accs = [results['INT8'][f'Top-{k}'] for k in k_values]\n",
    "\n",
    "        x = np.arange(len(k_values))\n",
    "        width = 0.35\n",
    "\n",
    "        ax.bar(x - width/2, fp32_accs, width, label='FP32', alpha=0.8)\n",
    "        ax.bar(x + width/2, int8_accs, width, label='INT8', alpha=0.8)\n",
    "\n",
    "        ax.set_xlabel('K')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_title('Top-K Accuracy ÂØπÊØî')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'Top-{k}' for k in k_values])\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 2. Á≤æÂ∫¶ÊçüÂ§±\n",
    "        ax = axes[0, 1]\n",
    "        deltas = [results['Delta'][f'Top-{k}'] for k in k_values]\n",
    "        colors = ['red' if d > 0 else 'green' for d in deltas]\n",
    "\n",
    "        ax.bar([f'Top-{k}' for k in k_values], deltas, color=colors, alpha=0.7)\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "        ax.set_ylabel('Á≤æÂ∫¶ÊçüÂ§±')\n",
    "        ax.set_title('INT8 vs FP32 Á≤æÂ∫¶ÊçüÂ§±')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 3. MRR ÂØπÊØî\n",
    "        ax = axes[1, 0]\n",
    "        mrr_vals = [results['FP32']['MRR'], results['INT8']['MRR']]\n",
    "        ax.bar(['FP32', 'INT8'], mrr_vals, alpha=0.7)\n",
    "        ax.set_ylabel('MRR')\n",
    "        ax.set_title('Mean Reciprocal Rank ÂØπÊØî')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 4. Áõ∏‰ººÂ∫¶ÂàÜÂ∏É\n",
    "        ax = axes[1, 1]\n",
    "        sim_dist_fp32 = results['FP32']['similarity_dist']\n",
    "        sim_dist_int8 = results['INT8']['similarity_dist']\n",
    "\n",
    "        labels = ['Ê≠£Á°ÆÂåπÈÖç', 'ÈîôËØØÂåπÈÖç']\n",
    "        fp32_vals = [sim_dist_fp32['correct_mean'], sim_dist_fp32['incorrect_mean']]\n",
    "        int8_vals = [sim_dist_int8['correct_mean'], sim_dist_int8['incorrect_mean']]\n",
    "\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "\n",
    "        ax.bar(x - width/2, fp32_vals, width, label='FP32', alpha=0.8)\n",
    "        ax.bar(x + width/2, int8_vals, width, label='INT8', alpha=0.8)\n",
    "\n",
    "        ax.set_ylabel('Âπ≥ÂùáÁõ∏‰ººÂ∫¶')\n",
    "        ax.set_title('Áõ∏‰ººÂ∫¶ÂàÜÂ∏ÉÂØπÊØî')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(MODEL_DIR / 'quantization_evaluation.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "# ==================== ‰ΩøÁî® ====================\n",
    "\n",
    "evaluator = CLIPEvaluator(\n",
    "    fp32_model_path=\"../../model/clip-text-encoder.onnx\",  # ÊîπÊàê image encoder\n",
    "    int8_model_path=\"../../model/clip-text-encoder-quant-int8.onnx\",  # ÊîπÊàêÈáèÂåñÁâà\n",
    "    image_dir=\"../../data/dataset/coco/val2017\",\n",
    "    annotations_path=\"../../data/dataset/coco/annotations/captions_val2017.json\"\n",
    ")\n",
    "\n",
    "results = evaluator.evaluate()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä CLIP ÈáèÂåñÂâçÂêéÂØπÊØîËØÑ‰º∞\n",
      "======================================================================\n",
      "\n",
      "üîç ÊèêÂèñ FP32 ÁâπÂæÅ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting fp32 image features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:05<00:00, 193.68it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 340\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;66;03m# ==================== ‰ΩøÁî® ====================\u001B[39;00m\n\u001B[1;32m    333\u001B[0m evaluator \u001B[38;5;241m=\u001B[39m CLIPEvaluator(\n\u001B[1;32m    334\u001B[0m     fp32_model_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../model/clip-text-encoder.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# ÊîπÊàê image encoder\u001B[39;00m\n\u001B[1;32m    335\u001B[0m     int8_model_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../model/clip-text-encoder-quant-int8.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# ÊîπÊàêÈáèÂåñÁâà\u001B[39;00m\n\u001B[1;32m    336\u001B[0m     image_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../data/dataset/coco/val2017\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    337\u001B[0m     annotations_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../data/dataset/coco/annotations/captions_val2017.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    338\u001B[0m )\n\u001B[0;32m--> 340\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 172\u001B[0m, in \u001B[0;36mCLIPEvaluator.evaluate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# ÊèêÂèñÁâπÂæÅ\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124müîç ÊèêÂèñ FP32 ÁâπÂæÅ...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 172\u001B[0m img_feats_fp32, img_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_image_features\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfp32\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m text_feats_fp32 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextract_text_features(\n\u001B[1;32m    174\u001B[0m     [ann[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcaption\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m ann \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoco[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mannotations\u001B[39m\u001B[38;5;124m'\u001B[39m][:\u001B[38;5;241m1000\u001B[39m]], \n\u001B[1;32m    175\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfp32\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    176\u001B[0m )\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124müîç ÊèêÂèñ INT8 ÁâπÂæÅ...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[3], line 60\u001B[0m, in \u001B[0;36mCLIPEvaluator.extract_image_features\u001B[0;34m(self, model_type)\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m---> 60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m, image_ids\n",
      "\u001B[0;31mValueError\u001B[0m: need at least one array to concatenate"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T17:21:35.094679131Z",
     "start_time": "2026-02-18T17:19:10.752463466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import clip\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==================== 1. Ê†∏ÂøÉËØÑ‰º∞Á±ª ====================\n",
    "class DualTowerEvaluator:\n",
    "    def __init__(self,\n",
    "                 fp32_image_path, fp32_text_path,\n",
    "                 int8_image_path, int8_text_path,\n",
    "                 image_dir, annotations_path):\n",
    "\n",
    "        self.image_dir = Path(image_dir)\n",
    "\n",
    "        print(f\"üì¶ Ê≠£Âú®Âä†ËΩΩ 4 ‰∏™Ê®°Âûã...\")\n",
    "        # ÂõæÂÉèÂ°î‰ºöËØù\n",
    "        self.sess_img_fp32 = ort.InferenceSession(str(fp32_image_path))\n",
    "        self.sess_img_int8 = ort.InferenceSession(str(int8_image_path))\n",
    "\n",
    "        # ÊñáÊú¨Â°î‰ºöËØù\n",
    "        self.sess_txt_fp32 = ort.InferenceSession(str(fp32_text_path))\n",
    "        self.sess_txt_int8 = ort.InferenceSession(str(int8_text_path))\n",
    "\n",
    "        # ÂõæÂÉèÈ¢ÑÂ§ÑÁêÜ (Standard CLIP transform)\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                std=[0.26862954, 0.26130258, 0.27577711]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # Âä†ËΩΩÊ†áÊ≥®\n",
    "        print(f\"üìÇ Ê≠£Âú®Âä†ËΩΩ COCO Ê†áÊ≥®...\")\n",
    "        with open(annotations_path) as f:\n",
    "            self.coco = json.load(f)\n",
    "\n",
    "    def _run_inference(self, session, input_data):\n",
    "        \"\"\"ÈÄöÁî®Êé®ÁêÜÂåÖË£ÖÂô®\"\"\"\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        return session.run(None, {input_name: input_data})[0]\n",
    "\n",
    "    def extract_image_features(self, precision='fp32', limit=1000):\n",
    "        \"\"\"ÊèêÂèñÂõæÂÉèÁâπÂæÅ (FP32 Êàñ INT8)\"\"\"\n",
    "        sess = self.sess_img_fp32 if precision == 'fp32' else self.sess_img_int8\n",
    "        features = []\n",
    "        valid_ids = []\n",
    "\n",
    "        # ‰ªÖ‰ΩøÁî®Ââç limit Âº†ÂõæÁâáËøõË°åÊµãËØï\n",
    "        target_images = self.coco['images'][:limit]\n",
    "\n",
    "        for img_info in tqdm(target_images, desc=f\"Extracting {precision.upper()} Images\"):\n",
    "            img_path = self.image_dir / img_info['file_name']\n",
    "\n",
    "            if not img_path.exists():\n",
    "                print(f\"‚ö†Ô∏è Êñá‰ª∂‰∏çÂ≠òÂú®: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 1. Âä†ËΩΩ‰∏éÈ¢ÑÂ§ÑÁêÜ\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                # shape: [1, 3, 224, 224], type: float32\n",
    "                img_tensor = self.preprocess(img).unsqueeze(0).numpy().astype(np.float32)\n",
    "\n",
    "                # 2. Êé®ÁêÜ\n",
    "                feat = self._run_inference(sess, img_tensor)\n",
    "\n",
    "                # 3. Áª¥Â∫¶ÂØπÈΩê (Èò≤Ê≠¢Êúâ‰∫õÊ®°ÂûãËæìÂá∫ (1, 512) Êúâ‰∫õËæìÂá∫ (512,))\n",
    "                features.append(feat.reshape(1, -1))\n",
    "                valid_ids.append(img_info['id'])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå ÂõæÁâá {img_info['file_name']} Êé®ÁêÜÂ§±Ë¥•: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not features:\n",
    "            raise ValueError(\"Ê≤°ÊúâÊèêÂèñÂà∞‰ªª‰ΩïÂõæÂÉèÁâπÂæÅÔºåËØ∑Ê£ÄÊü•Ë∑ØÂæÑËÆæÁΩÆÔºÅ\")\n",
    "\n",
    "        return np.concatenate(features, axis=0), valid_ids\n",
    "\n",
    "    def extract_text_features(self, image_ids, precision='fp32'):\n",
    "        \"\"\"ÊèêÂèñÂØπÂ∫îÂõæÁâáÁöÑÊñáÊú¨ÊèèËø∞ÁâπÂæÅ\"\"\"\n",
    "        sess = self.sess_txt_fp32 if precision == 'fp32' else self.sess_txt_int8\n",
    "        features = []\n",
    "\n",
    "        # ÊûÑÂª∫ image_id Âà∞ caption ÁöÑÊò†Â∞Ñ\n",
    "        img_to_caption = {}\n",
    "        for ann in self.coco['annotations']:\n",
    "            if ann['image_id'] not in img_to_caption:\n",
    "                img_to_caption[ann['image_id']] = ann['caption'] # ÂèñÁ¨¨‰∏ÄÊù°ÊèèËø∞\n",
    "\n",
    "        # Êåâ image_ids ÁöÑÈ°∫Â∫èÊèêÂèñÂØπÂ∫îÁöÑÊñáÊú¨\n",
    "        valid_captions = []\n",
    "        for img_id in image_ids:\n",
    "            if img_id in img_to_caption:\n",
    "                valid_captions.append(img_to_caption[img_id])\n",
    "            else:\n",
    "                valid_captions.append(\"a photo\") # ÂÖúÂ∫ïÁ≠ñÁï•\n",
    "\n",
    "        for caption in tqdm(valid_captions, desc=f\"Extracting {precision.upper()} Texts\"):\n",
    "            try:\n",
    "                # 1. Tokenize (Âº∫Âà∂ int64)\n",
    "                tokens = clip.tokenize([caption]).cpu().numpy().astype(np.int64)\n",
    "\n",
    "                # 2. Êé®ÁêÜ\n",
    "                feat = self._run_inference(sess, tokens)\n",
    "                features.append(feat.reshape(1, -1))\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå ÊñáÊú¨ '{caption[:20]}...' Êé®ÁêÜÂ§±Ë¥•: {e}\")\n",
    "\n",
    "        return np.concatenate(features, axis=0)\n",
    "\n",
    "    # ==================== 2. ËÆ°ÁÆóÊåáÊ†á ====================\n",
    "\n",
    "    def calculate_metrics(self, img_feats, txt_feats):\n",
    "        \"\"\"ËÆ°ÁÆóÊ†∏ÂøÉÊ£ÄÁ¥¢ÊåáÊ†á\"\"\"\n",
    "        # 1. L2 ÂΩí‰∏ÄÂåñ\n",
    "        img_feats /= np.linalg.norm(img_feats, axis=1, keepdims=True)\n",
    "        txt_feats /= np.linalg.norm(txt_feats, axis=1, keepdims=True)\n",
    "\n",
    "        # 2. ËÆ°ÁÆóÁõ∏‰ººÂ∫¶Áü©Èòµ (N x N)\n",
    "        sim_matrix = txt_feats @ img_feats.T\n",
    "        n_samples = sim_matrix.shape[0]\n",
    "\n",
    "        # 3. ËÆ°ÁÆó Recall@K\n",
    "        # ÂØπÊØè‰∏ÄË°å(Text)ÔºåÊ≠£Á°ÆÁöÑ Image Â∫îËØ•Âú®ÂØπËßíÁ∫ø‰ΩçÁΩÆ (Á¥¢Âºï i)\n",
    "        # Ëé∑ÂèñÊØè‰∏ÄË°åÁõ∏‰ººÂ∫¶‰ªéÂ§ßÂà∞Â∞èÁöÑÁ¥¢Âºï\n",
    "        top_indices = np.argsort(-sim_matrix, axis=1)\n",
    "\n",
    "        metrics = {}\n",
    "        for k in [1, 5, 10]:\n",
    "            correct_count = 0\n",
    "            for i in range(n_samples):\n",
    "                # Ê£ÄÊü• ground truth (i) ÊòØÂê¶Âú®Ââç k ‰∏™È¢ÑÊµã‰∏≠\n",
    "                if i in top_indices[i, :k]:\n",
    "                    correct_count += 1\n",
    "            metrics[f\"R@{k}\"] = correct_count / n_samples * 100\n",
    "\n",
    "        # 4. ËÆ°ÁÆó MRR\n",
    "        mrr_sum = 0\n",
    "        for i in range(n_samples):\n",
    "            # ÊâæÂà∞Ê≠£Á°ÆÁ≠îÊ°à i Âú®ÊéíÂ∫èÂêéÁöÑ‰ΩçÁΩÆ (rank ‰ªé 1 ÂºÄÂßã)\n",
    "            # np.where ËøîÂõûÁöÑÊòØ tuple\n",
    "            rank = np.where(top_indices[i] == i)[0][0] + 1\n",
    "            mrr_sum += 1.0 / rank\n",
    "        metrics[\"MRR\"] = mrr_sum / n_samples\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def evaluate(self, limit=1000):\n",
    "        print(\"\\nüöÄ ÂºÄÂßãÂÖ®Èáè Pipeline ÂØπÊØîËØÑ‰º∞...\")\n",
    "\n",
    "        # 1. FP32 ÈìæË∑Ø\n",
    "        print(\"\\nüîµ --- Running FP32 Pipeline ---\")\n",
    "        img_fp32, ids = self.extract_image_features('fp32', limit)\n",
    "        txt_fp32 = self.extract_text_features(ids, 'fp32')\n",
    "        res_fp32 = self.calculate_metrics(img_fp32, txt_fp32)\n",
    "\n",
    "        # 2. INT8 ÈìæË∑Ø\n",
    "        print(\"\\nüü† --- Running INT8 Pipeline ---\")\n",
    "        img_int8, _ = self.extract_image_features('int8', limit)\n",
    "        txt_int8 = self.extract_text_features(ids, 'int8')\n",
    "        res_int8 = self.calculate_metrics(img_int8, txt_int8)\n",
    "\n",
    "        # 3. ÊâìÂç∞ÂØπÊØîÊä•Âëä\n",
    "        self.print_report(res_fp32, res_int8)\n",
    "        self.plot_comparison(res_fp32, res_int8)\n",
    "\n",
    "    def print_report(self, fp32, int8):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{'Metric':<10} | {'FP32':<10} | {'INT8':<10} | {'Drop':<10}\")\n",
    "        print(\"-\" * 60)\n",
    "        for k in ['R@1', 'R@5', 'R@10', 'MRR']:\n",
    "            v1 = fp32.get(k, 0)\n",
    "            v2 = int8.get(k, 0)\n",
    "            # MRR‰øùÁïô4‰ΩçÂ∞èÊï∞ÔºåR@K‰øùÁïô2‰Ωç\n",
    "            fmt = \".4f\" if k == 'MRR' else \".2f\"\n",
    "            diff = v1 - v2\n",
    "            print(f\"{k:<10} | {v1:{fmt}} | {v2:{fmt}} | {diff:{fmt}}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "    def plot_comparison(self, fp32, int8):\n",
    "        labels = ['R@1', 'R@5', 'R@10']\n",
    "        v1 = [fp32[k] for k in labels]\n",
    "        v2 = [int8[k] for k in labels]\n",
    "\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(x - width/2, v1, width, label='FP32', color='#4e79a7')\n",
    "        plt.bar(x + width/2, v2, width, label='INT8', color='#f28e2b')\n",
    "\n",
    "        plt.ylabel('Recall (%)')\n",
    "        plt.title('End-to-End Retrieval Performance: FP32 vs INT8')\n",
    "        plt.xticks(x, labels)\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # ‰øùÂ≠òÂõæÁâá\n",
    "        plt.savefig(\"../../model/final_comparison.png\")\n",
    "        plt.show()\n",
    "\n",
    "# ==================== 3. ËøêË°åÂÖ•Âè£ ====================\n",
    "\n",
    "# Ë∑ØÂæÑÈÖçÁΩÆ (ËØ∑Á°Æ‰øùËøô 4 ‰∏™Êñá‰ª∂ÈÉΩÂ≠òÂú®)\n",
    "fp32_img_path = \"../../model/clip-image-encoder.onnx\"\n",
    "fp32_txt_path = \"../../model/clip-text-encoder.onnx\"\n",
    "\n",
    "int8_img_path = \"../../model/clip-image-encoder-quant-int8.onnx\"\n",
    "int8_txt_path = \"../../model/clip-text-encoder-quant-int8.onnx\"\n",
    "\n",
    "# Êï∞ÊçÆÈõÜË∑ØÂæÑ\n",
    "coco_img_dir = \"../../data/dataset/coco/val2017\"\n",
    "coco_ann_path = \"../../data/dataset/coco/annotations/captions_val2017.json\"\n",
    "\n",
    "evaluator = DualTowerEvaluator(\n",
    "    fp32_img_path, fp32_txt_path,\n",
    "    int8_img_path, int8_txt_path,\n",
    "    coco_img_dir, coco_ann_path\n",
    ")\n",
    "\n",
    "# ÊâßË°åËØÑ‰º∞ (‰ΩøÁî®Ââç 1000 Âº†Âõæ‰Ωú‰∏∫ÊµãËØïÈõÜ)\n",
    "evaluator.evaluate(limit=1000)"
   ],
   "id": "def1d2d158558ccf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Ê≠£Âú®Âä†ËΩΩ 4 ‰∏™Ê®°Âûã...\n",
      "üìÇ Ê≠£Âú®Âä†ËΩΩ COCO Ê†áÊ≥®...\n",
      "\n",
      "üöÄ ÂºÄÂßãÂÖ®Èáè Pipeline ÂØπÊØîËØÑ‰º∞...\n",
      "\n",
      "üîµ --- Running FP32 Pipeline ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting FP32 Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:06<00:00, 15.01it/s]\n",
      "Extracting FP32 Texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:14<00:00, 67.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü† --- Running INT8 Pipeline ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting INT8 Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:52<00:00, 19.04it/s]\n",
      "Extracting INT8 Texts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:09<00:00, 105.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Metric     | FP32       | INT8       | Drop      \n",
      "------------------------------------------------------------\n",
      "R@1        | 49.40 | 49.50 | -0.10\n",
      "R@5        | 79.20 | 77.60 | 1.60\n",
      "R@10       | 88.50 | 88.30 | 0.20\n",
      "MRR        | 0.6242 | 0.6205 | 0.0037\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
